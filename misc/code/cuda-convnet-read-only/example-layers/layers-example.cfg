# This is a layer configuration file that contains all the 
# layer types supported by this code. It's not actually good for anything
# other than demonstrating how layers are specified and connected to one another.

# Note: this file has gotten so big that the resultant net will not run on anything short of a 3GB GTX 580.
# But there's no particular reason to run the net specified by this file. It's not actually good.

[data]
type=data
dataIdx=0

[labels]
type=data
dataIdx=1

[conv32]
type=conv
inputs=data
channels=3
filters=32
padding=4
stride=1
filterSize=9
neuron=logistic
initW=0.00001
partialSum=1
sharedBiases=true

[local32]
type=local
inputs=conv32
channels=32
filters=32
padding=4
stride=1
filterSize=9
neuron=logistic
initW=0.00001

[fc1024]
type=fc
outputs=1024
inputs=data
initW=0.001
neuron=relu

[maxpool]
type=pool
pool=max
inputs=local32
start=0
sizeX=4
stride=2
outputsX=0
channels=32

[rnorm1]
type=rnorm
inputs=maxpool
channels=32
sizeX=5
scale=0.0000125
pow=0.75

[cnorm1]
type=cnorm
inputs=rnorm1
channels=32
sizeX=7
scale=0.001
pow=0.5

[conv32-2]
type=conv
inputs=cnorm1
groups=4
channels=32
filters=32
padding=2
stride=1
filterSize=5
neuron=relu
initW=0.0001
partialSum=1
sharedBiases=false

[conv32-3]
type=conv
inputs=conv32-2
groups=4
channels=128
filters=32
padding=2
stride=2
filterSize=5
neuron=relu
initW=0.0001
partialSum=1
randSparse=true
filterChannels=64

[fc10]
type=fc
outputs=10
inputs=conv32-3,fc1024
initW=0.0001,0.0001
neuron=ident

[probs]
type=softmax
inputs=fc10

[logprob]
type=cost.logreg
inputs=labels,probs
