image blur. The results are better than for viewpoint and scale changes, especially for the structured scene. All detectors have nearly horizontal repeatability curves, showing a high level of invariance to image blur, except for the MSER detector, which is clearly more sensitive to this type of transformation. This is becausetheregionboundariesbecomesmooth,andthesegmentation process is less accurate. The number of corresponding regions detected on structured scene is much lower than for the textured scene and it changes byadifferentfactorfordifferentdetectors.Thisclearlyshows that the detectors respond to different features. The repeatability for the EBR detector is very low for the textured scene. This can be explained by the lack of stable edges, on which the region extraction is based. JPEG Artifacts. Figure 19 shows the score for the JPEG compression sequence from Fig. 9(g). For this type of structured scene (buildings), with large homo- geneous areas and distinctive corners, Hessian-Affine and Harris-Affine are clearly best suited. The degrada- tion under increasing compression artefacts is similar for all detectors. 

Light Change. Figure 20 shows the results for light changes for the images on Fig. 9(h). All curves are nearly horizontal, showing good robustness to 

illumination changes, although the MSER obtains the highest repeatability score for this type of scene. The absolutescoreshowshowasmalltransformationofthistype of a scene can affect the repeatability of different detectors. General Conclusions. For most experiments the MSER regions or Hessian-Affine obtain the best re- peatability score and are followed by Harris-Affine. Salient regions give relatively low repeatability. For the edge-based region detector, it largely depends on the scene content, i.e., whether the image contains sta- ble curves or not. The intensity extrema-based region detector gives average scores. Results largely depend on the type of scene used for the experiments. Again, this illustrates the complementarity of the various de- tectors. Depending on the application, a combination of detectors is probably prudent. Viewpoint changes are the most difficult type of transformation to cope with, followed by scale changes. All detectors behave similarly under the dif- ferent types of transformations, except for the blur se- quenceofFig.17,whereMSERperformssignificantlyworse than the others. In the majority of the examples Hessian-Affine and Harris-Affine detector provide several times more corresponding regions than the other detectors. The Hessian-Affine detector almost systematically outper- forms the Harris-Affine detector, and the same holds for MSER with respect to IBR. 

4.3. More Detailed Tests Tofurthervalidateourexperimentalsetupandtoobtaina deeper insight in what is actually going on, a more detailed analysis is performed on one image pair with a viewpoint change of 40 degrees, namely the first and thirdcolumnofthegraffitisequenceshowninFig.9(a). Accuracy of the Detectors. First, we test the effect of our choice for the overlap error threshold. This was fixed to 40% in all the previous experiments. Choosing a lower threshold results in more accurate regions, (see Fig. 12). Figure 21(a) shows the repeatability score as a function of the overlap error. Clearly, as the re- quired overlap is relaxed, more regions are qualified as corresponding, and the repeatability scores go up. The relative ordering of the various detectors remains virtually the same, except for the Harris-Affine and Hessian region detectors. They improve their ranking with increasing overlap error, which means that these detectors are less accurate than the others–at least for this type of scene. 

ChoiceofNormalizedRegionSize. Next,wetestthe effect of our choice of the normalized region size. This was fixed to a radius of 30 pixels in all the previous experiments. Figure 21(b) shows how the repeatability scores vary as a function of the normalized region size, with the overlap error threshold fixed to 40%. The relative ordering of the different detectors stays the 

Varying the Region Density. For some detectors, it ispossibletovarythenumberofdetectedregions,sim-ply by changing the value of one significant parameter. This makes it possible to compensate for the effect that different region densities might have on the repeatabil- ity scores and compare different detectors when they output similar number of regions. Figure 21(c) shows thattherepeatabilityofMSER(92%)andIBR(63%)ishigh for a small number of regions (70) and decreases to 68% and 50% respectively for 350 detected regions, unlike the repeatability for Hessian-Laplace, Harris- Laplace and salient regions which is low for a small number of regions and increases for more than 300 regions. However, the rank of the detectors remains the same in the range of available threshold settings, therefore the order of the detectors in the experiments in the previous section is not affected by the density of regions. Depending on the application and the re- quired number of regions one can set the appropriate threshold to optimize the performance. 

approach would be to only compare regions of similar sizes. This results in a plot showing the repeatability scores for different detectors as a function of region size. Large regions typically yield higher repeatabil- ity scores, not only because of their intrinsic stability, but also because they automatically yield lower over- lap errors. Figure 21(d) shows the repeatability with respect to detected region size. MSER detector has the highest repeatability score and it is nearly the same for different size of the detected regions. The results for Hessian-Affine, Harris-Affine and IBR are similar. The repeatability is low for small regions, then it in- creases for medium size regions and slightly decreases forlargerregionsexceptthatthescoreforHarris-Affinedecreases more rapidly. The repeatability for EBR and salient regions is small for small and medium size re- gions and increases for large regions. Note, that the repeatability for different region size depends also on the type of image transformation i.e., for large scale changes only the small regions from one image will match with the large regions from the other one. 

5. Matching Experiments 

Intheprevioussection,theperformanceofthedifferentregion detectors is evaluated from a rather theoretical point of view, focusing on the overlap error and re- peatability. In this section, we follow a more practical approach. In a practical application, regions need to be 

matched or clustered, and apart from the accuracy and repeatabilityofthedetection,alsothedistinctivenessofthe region is important. We test how well the regions can be matched, looking at the number of matches found as well as the ratio between correct matches and mismatches.To this end, we compute a descriptor for the regions, and then check to what extent matching with the de- scriptorgivesthecorrectregionmatch.HereweusetheSIFT descriptor of Lowe (1999). This descriptor gave the best matching results in an evaluation of differ- ent descriptors computed on scale and affine invariant regions (Mikolajczyk and Schmid, 2003, 2005). The descriptor is a 128 dimensional vector computed from the spatial distribution of image gradients over a cir- cular region. To this end, each elliptical region is first mapped to a circular region of 30 × 30 pixels, and rotated based on the dominant gradient orientation, to compensate for the affine geometric deformations, as shown in Fig. 2(e). Note that unlike in Section 4, this mapping concerns descriptors; the region size is coin- cidentally the same (30 Pixels). 

5.1. Matching Score Again the measure is computed between a reference image and the other images in a set. The matching score is computed in two steps. 


1. A region match is deemed correct if the overlap error defined in the previous section is minimal and less than 40%, i.e., ?O = 0.4. This provides the ground truth for correct matches. Only a single match is allowed for each region. 2. The matching score is computed as the ratio be- tween the number of correct matches and the smaller number of detected regions in the pair of images. A match is the nearest neighbour in the de- scriptor space. The descriptors are compared with the Euclidean distance. 

This test gives an idea on the distinctiveness of fea- tures.Theresultsareratherindicativethanquantitative.If the matching results do not follow those of the re- peatability test for a particular feature type that means that the distinctiveness of these features differs from the distinctiveness of other detectors. 

TheEffectofRescalingtheRegions. Here,theissue arises on what scale to compute the descriptor for a given region. Indeed, rather than taking the original distinguished region, one might also rescale the region first, which typically leads to more discriminative power–certainly for the small regions. Figure 22(c) shows how the matching score for the different de- tectors varies for different scale factors. Typically, the curves go slightly up for larger measurement regions, except for EBR and salient regions which attain their maximumscoreforscalefactorof2and3respectively. 


5.2. Matching Under Various Transformations Figures 13 –20(c) and (d) give the results of the match- ing experiment for the different types of transforma- tions. These are basically the same plots as given in Figs. 13–20(a) and (b) but now focusing on regions that have actually been matched, rather than just cor- responding regions. Formosttransformations,theplotslookindeedvery similar to (albeit a bit lower than) the results obtained with the overlap error test. This indicates that the re- gions typically have sufficient distinctiveness to be matched automatically. One should be careful though to generalize these results because these might be sta- tistically unreliable, e.g. for much larger numbers of features in database retrieval. Sometimes, the score or relative ordering of the de- tectors differs significantly from the overlap error tests of the previous section (e.g. Figs. 17 and 20). This means that the regions found by some detectors are not distinctive and many mismatches occur. 

The ranking of the detectors changes in Fig. 20(c) comparingtoFig.20(a)whichmeanstheHarris-AffineandHessian-Affinearelessdistinctive.Thesedetectorsfind several slightly different regions containing the same local structure all of which have a small overlap error.Thus,thematchedregionsmighthavetheoverlapsmaller than 40% but the minimum overlap error is for a slightly different region. In this way the matched regions are counted as incorrect. The same change in ranking for Harris-Affine and Hessian-Affine can be observed on the results for other transformations. However the rank of the fig. (d) showing the number of matched regions do not change with r espect to the number of corresponding regions on figures (b). The curves for Fig. 18(c) and (d) give the results for the textured scene shown in Fig. 9(f). For this case, the matching scores are significantly lower than the repeatability scores obtained earlier. This can be ex- plainedbythefactthatthescenecontainsmanysimilarlocal structures, that can hardly be distinguished. 

Ratio Between Correct and False Matches. So far, we investigated the matching capability of corre- sponding regions. In a typical matching application, what matters is the ratio between correct matches and false matches, i.e., are the regions within a correct match more similar to each other than two regions that do not correspond but accidentally look more or less 


similar ? Here, the accuracy of the region detection plays a role, as does the variability of the intensity patterns for all regions found by a detector, i.e., the distinctiveness. Figure 22(a) shows the percentage of correct matches as a function of the number of matches. A match is the nearest neighbour in the SIFT feature space. These curves were obtained by ranking the matches based on the distance between the nearest neighbours. To obtain the same number of matches for different detectors the threshold was individually changed for each region type. As the threshold, therefore the number of matches increases (Fig. 22(a)), the number of correct as well as false matches also increases, but the num- ber of false matches increases faster, hence the percentage of correct matches drops. For a good detector, a small threshold results in almost ex- clusively correct matches. Figure 22(b) shows the absolute number of correct matches with respect to the total number of matches. We observe that MSER and IBR provide a large number of correct matches for a small descriptor threshold. Up to 100 matches more than 90% are correct. This means one does not have to rely so heavily on semi-local or global consistency checks to remove the false matches afterwords. Harris-Affine and Hessian-Affine obtain low score but improve when the distance is larger. 
Depending on the application, the number of matches a user is interested in may vary. If only a very small number of matches is needed (e.g. for com- puting epipolar geometry), the MSER or IBR detector is the best choice for this type of scene. Above 200 matches, Hessian-Affine and Harris-Affine perform better–albeit at the cost of a large false positive rate. 

6. Conclusions In this paper we have presented the state of the art on affine covariant region detectors and have compared their performance. The comparison has shown that the performanceofallpresenteddetectorsdeclinesslowly,withsimilarrates,asthechangeofviewpointincreases.There does not exist one detector which outperforms the other detectors for all scene types and all types of transformations. In many cases the highest score is obtained by the MSER detector, followed by Hessian- Affine.MSERperformswellonimagescontainingho-mogeneous regions with distinctive boundaries. This also holds for IBR since both methods are designed for similar region types. Hessian-Affine and Harris-Affine provide more regions than the other detectors, which is useful in matching scenes with occlusion and clut- ter. EBR is suitable for scenes containing intersections of edges. Salient regions obtained low scores in this evaluation but performed well in the context of object class recognition (Kadir et al., 2004). The detectors are complementary, i.e., they extract regions with different properties and the overlap of these regions is small if not empty. Several detectors should be used simultaneously to obtain the best per- formance. The output of different detectors can be combined by concatenating the respective matches. This increases the number of matches and therefore the robustness to occlusion, at the expense of process- ing time. The choice of the optimal subset depends on the context, for example on the required number of extracted regions and processing time. In general, matchingondescriptorsaloneisnotsufficient(assomeare mismatched), and further steps are required to dis- ambiguate matches (Ferrari et al., 2004; Rothganger et al.,2003;SchaffalitzkyandZisserman,2002;SivicandZisserman, 2003). These steps depend on the applica- tion, but generally use methods of geometric filtering based on the local spatial arrangement of the regions, or on multiple view geometric relations. Anothercontributionofthepaperisthecarefullyde- signed test protocol which is available on the Internet togetherwiththetestdata.Thisallowstheevaluationoffuture detectors and their comparison with those stud- ied in the paper. Note that the criteria, as defined here, areonlyvalidforplanarscenesorinthecaseofcamerarotation or zoom. Only in these cases is the geometric relationbetweentwoimagesdefinedbyahomography.However, many 3D objects are composed of smooth surfaces, which are planar in the small–that is, suffi- cientlysmallpatchescanbetreatedasbeingcomprisedof coplanar points. Naturally, regions are also detected at depth and surface orientation discontinuities of 3D scenes. Evaluating the repeatability of such regions is beyond the scope of this paper. Research on covariant regions and their description is now well advanced–they are the building blocks for general recognition systems–but more remains to be done. One direct generalization is to apply the detec- tors to representations of the image other than inten- sity, for example ordering functions such as ‘satura- tion’ or ‘projection on the red-blue direction in RGB space’ could be used. Furthermore, affine detectors for shape (object boundaries) or completely unstructured textures should be developed. Finally, an important is- sue is how to design detectors for images of an object class, where there is within-class variation in addition to affine viewpoint changes, and how to measure their repeatability (Kadir et al., 2004). 

